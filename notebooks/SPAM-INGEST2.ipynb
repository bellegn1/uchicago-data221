{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam =pd.read_csv(\"../data/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might have seen this error message before; \n",
    "# there are symbols in the data file that are invalid \n",
    "# unicode characters.  Apparently this file isn't\n",
    "# in unicode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam =pd.read_csv(\"../data/spam.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.iloc[:,3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, I don't know what those last three columns are for, but I don't like them.\n",
    "spamclean = []\n",
    "for line in open(\"spam.csv\", encoding=\"latin-1\"):\n",
    "        a = line.find(\",\")\n",
    "        spamclean.append((line[0:a], line[a+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.DataFrame(spamclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = spam.drop(labels=0, axis=0)  #only do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam =spam.rename({0: \"label\", 1:\"text\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes.. \n",
    "s1 = spam.query(\"label == 'ham'\")\n",
    "s2 = spam.query(\"label == 'spam'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two giant strings... \n",
    "s1text = s1.text.str.cat()\n",
    "s2text = s2.text.str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the strings (proably split on whitespace)\n",
    "tok1 = nltk.word_tokenize(s1text)\n",
    "tok2 = nltk.word_tokenize(s2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And create frequency distribution objects.\n",
    "d1 = nltk.FreqDist(tok1)\n",
    "d2 = nltk.FreqDist(tok2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1  # This will act like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These methods look like number of token counts\n",
    "d1.N(), d2.N()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and these look like the number of distinct tokens.\n",
    "len(d1.keys()), len(d2.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten thousand words.  This is reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = \"Hey, what's up rich?\"\n",
    "teststring2 = \"Do you want free airtime?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the frequency data I need.\n",
    "# Word, ham_occur, ham_total, spam_occur, spam_total\n",
    "print(\"Word\\tham_occ\\tham_tot\\tspam_occ\\tspam_tot\")\n",
    "\n",
    "for token in nltk.word_tokenize(teststring):\n",
    "    print(token, '\\t', end=\"\" )\n",
    "    print(d1[token] , '\\t',  d1.N(),'\\t', d2[token], \n",
    "          '\\t', d2.N())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = [\"Hey there, I am Maya with GP Research. We're surveying IL residents. Can you respond to a few questions?\",\n",
    "           \"Headed down now.\",\n",
    "\"The banana chocolate bread is delicious! All that’s left is one small heel, which I will dunk in my coffee tomorrow.\",\n",
    "\"Hurry! For a limited time, add a FREE line to your account. Really, it's on us–no strings attached.\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to reorganize the data from two dictionaries into a dataframe \n",
    "# so I can make scatterplots.\n",
    "counts = pd.DataFrame()\n",
    "for k in set(d1.keys()).union(set(d2.keys())):\n",
    "    counts = counts.append( { \"word\": k , \"d1\": d1[k], \"d2\": d2[k]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make the plot more expressive by putting labels on the dots, since each\n",
    "# dot is a word.  Because of flaws in matplotlib, we have to use ugly log10 axes here;\n",
    "# plotting labels on points does not play nicely with log-log axes.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ranks = counts.sort_values(\"d1\", ascending=False).reset_index()\n",
    "\n",
    "ax.scatter(np.log10(ranks.index), np.log10(ranks.d1+0.1))\n",
    "ax.set_xlabel(\"log10 word rank\")\n",
    "ax.set_ylabel(\"log10 word count\")\n",
    "\n",
    "ax.grid()\n",
    "for i in np.power(10, np.linspace(0,4,100)).astype(\"int\"):\n",
    "        ax.text(np.log10(ranks.index[i])+0.2, np.log10(ranks.loc[i,\"d1\"]+.1), ranks.loc[i,\"word\"],  fontsize=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.loglog(counts.d1/d1.N(), counts.d2/d2.N(),'.')\n",
    "ax.plot([1E-4,1E-1], [1E-4,1E-1], color='k', linestyle='-',linewidth=0.5)\n",
    "ax.set_xlabel('Ham frequencies (log scale)')\n",
    "ax.set_ylabel('Spam frequencies (log scale)')\n",
    "for i in counts.index:\n",
    "    if counts.loc[i, \"d1\"] + counts.loc[i, \"d2\"] >=50 :\n",
    "        ax.annotate( counts.loc[i,\"word\"], ((counts.loc[i, \"d1\"]+.1)/d1.N(), (counts.loc[i,\"d2\"]+.1)/d2.N()), fontsize=8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.loglog(counts.d1+counts.d2, counts.d1/d1.N()/counts.d2*d2.N(),'.')\n",
    "#ax.plot([1,1E-1], [1,1E-1], color='k', linestyle='-',linewidth=0.5)\n",
    "ax.set_xlabel('odds ratio in favor of ham')\n",
    "ax.set_ylabel('number of occurrences total')\n",
    "for i in counts.index:\n",
    "    if counts.loc[i, \"d1\"] + counts.loc[i, \"d2\"] >=50 :\n",
    "       ax.annotate( counts.loc[i,\"word\"], (counts.loc[i, \"d1\"]+counts.loc[i, \"d2\"], \n",
    "                (counts.loc[i, \"d1\"]+.1)/d1.N()/(counts.loc[i,\"d2\"]+.1)*d2.N()), fontsize=8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
